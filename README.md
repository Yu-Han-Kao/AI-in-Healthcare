# AI-in-Healthcare
How Explainability and Trust Shape User Acceptance of AI in Healthcare

To explore the adoption of AI in healthcare, this study applies the extended Technology Acceptance Model (TAM) to investigate how AI explanations and trust affect users' acceptance of AI doctors in a virtual reality (VR) consultation environment. Participants were randomly assigned to a basic or detailed explanation group and completed self-reported questionnaires and physiological measurements. The collected data were analysed using regression analysis, Random Forest models, and Large Language Models (LLMs).

The results demonstrate that trust in the AI doctor is the strongest predictor of user acceptance. Detailed explanations enhanced acceptance, while eye-blinking duration showed a positive correlation, and trust in human doctors negatively correlated with the AI doctor's acceptance. Furthermore, the summary from LLM highlighted users' emphasis on clarity, credible sources, and simple instructions, alongside concerns regarding limited interaction, autonomy, and personalisation.

